{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lemmas...\n",
      "Classified lemmas saved to 'classified_lemmas_merged.csv'.\n",
      "   Doc                          Emotions  \\\n",
      "0    0                 neutral | sadness   \n",
      "1    1                   neutral | anger   \n",
      "2    2  anger | fear | neutral | sadness   \n",
      "3    3                   neutral | anger   \n",
      "4    4            fear | neutral | anger   \n",
      "\n",
      "                                              Topics  \n",
      "0  crime | environment | health | entertainment |...  \n",
      "1  technology | crime | environment | entertainme...  \n",
      "2  technology | crime | environment | health | ed...  \n",
      "3        money | crime | entertainment | environment  \n",
      "4  crime | environment | health | education | ent...  \n"
     ]
    }
   ],
   "source": [
    "# Load the classifiers\n",
    "emotion_classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", truncation=True)\n",
    "topic_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", truncation=True)\n",
    "\n",
    "# Define possible categories for topic classification\n",
    "categories = [\"money\", \"politics\", \"crime\", \"technology\", \"health\", \"education\", \"environment\", \"sports\", \"entertainment\"]\n",
    "\n",
    "# Load dataset (adjust the file path and delimiter as needed)\n",
    "df = pd.read_csv(\"../../dataset/processed/topics_formatted.csv\", sep=\",\")  # Adjust file path and delimiter as needed\n",
    "\n",
    "# Extract document numbers and lemmas\n",
    "doc_numbers = df['Dataset']  # Assuming the first column is named 'Doc'\n",
    "lemmas = df['Sentence']  # Assuming the column is named 'Lemma'\n",
    "\n",
    "# Initialize dictionary for storing merged results\n",
    "merged_results = defaultdict(lambda: {\"Emotions\": set(), \"Topics\": set()})\n",
    "\n",
    "# Process each  \n",
    "print(\"Processing lemmas...\")\n",
    "for i, (doc_number, lemma) in enumerate(zip(doc_numbers, lemmas), 1):\n",
    "    # Split the lemma column into individual lemmas (assume comma-separated)\n",
    "    individual_lemmas = lemma.split(\" \")\n",
    "\n",
    "    for single_lemma in individual_lemmas:\n",
    "        # Classify emotion\n",
    "        emotion_predictions = emotion_classifier(single_lemma.strip())\n",
    "        dominant_emotion = emotion_predictions[0]['label']  # Most probable emotion\n",
    "\n",
    "        # Classify topic\n",
    "        topic_predictions = topic_classifier(single_lemma.strip(), candidate_labels=categories)\n",
    "        dominant_topic = topic_predictions['labels'][0]  # Most probable topic\n",
    "\n",
    "        # Merge results for the same document number\n",
    "        merged_results[doc_number][\"Emotions\"].add(dominant_emotion)\n",
    "        merged_results[doc_number][\"Topics\"].add(dominant_topic)\n",
    "\n",
    "    # Print progress every 10 lemmas (adjust frequency as needed)\n",
    "    if i % 10 == 0 or i == len(lemmas):\n",
    "        print(f\"Processed {i}/{len(lemmas)} lemmas.\", end=\"\\r\")\n",
    "\n",
    "# Prepare the final results DataFrame\n",
    "final_results = []\n",
    "for doc_number, data in merged_results.items():\n",
    "    final_results.append({\n",
    "        \"Doc\": doc_number,\n",
    "        \"Emotions\": \" | \".join(data[\"Emotions\"]),\n",
    "        \"Topics\": \" | \".join(data[\"Topics\"])\n",
    "    })\n",
    "\n",
    "final_results_df = pd.DataFrame(final_results)\n",
    "\n",
    "# Save results to a CSV file\n",
    "final_results_df.to_csv(\"../../dataset/processed/classified_lemmas_merged.csv\", index=False)\n",
    "print(\"Classified lemmas saved to 'classified_lemmas_merged.csv'.\")\n",
    "\n",
    "# Display the first few rows of the results DataFrame\n",
    "print(final_results_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
